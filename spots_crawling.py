from requests_html import HTMLSession
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from datetime import datetime
from datetime import timedelta

today = datetime.today().strftime("%Y%m%d")
yesterday = (datetime.today() - timedelta(days=1)).strftime("%Y%m%d")
date = iter([today, yesterday])

# í¬ë¡¤ë§í•  URL ëª©ë¡ (ë‚¨ì„±, ì—¬ì„±, í‚¤ì¦ˆ)
sports_ruls = {
    "https://sports.news.naver.com/ranking/index.nhn?date=" + next(date),
    "https://sports.news.naver.com/ranking/index.nhn?date=" + next(date)
}

def crawl_sports():
    # ì„¸ì…˜ ì‹œì‘
    session = HTMLSession()

    # ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    all_items = []

    # ê° ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ í¬ë¡¤ë§ ì‹¤í–‰
    for page_num, url in enumerate(sports_ruls, start=1):
        print(f"ğŸ” ìŠ¤í¬ì¸  ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì¤‘...")
        response = session.get(url)

        # JavaScript ë Œë”ë§ ì‹¤í–‰ (3ì´ˆ ëŒ€ê¸°)
        response.html.render(sleep=3)

        # HTML íŒŒì‹±
        soup = BeautifulSoup(response.html.html, "html.parser")

        # ë‚¨ì„±ê³¼ ì—¬ì„±: ul í•˜ìœ„ì˜ liì—ì„œ ì¶”ì¶œ
        ul_tag = soup.find("div", class_="news_list ranking")
        if ul_tag:
            li_tags = ul_tag.find_all("li")  # ëª¨ë“  li íƒœê·¸ ì°¾ê¸°
            
            for li in li_tags:
                a_tag = li.find("a")
                href = urljoin(url, a_tag["href"]) if a_tag else None  # ìƒëŒ€ ê²½ë¡œ -> ì ˆëŒ€ ê²½ë¡œ ë³€í™˜

                img_tag = li.find("img")
                img_src = urljoin(url, img_tag["src"]) if img_tag else None  # ìƒëŒ€ ê²½ë¡œ -> ì ˆëŒ€ ê²½ë¡œ ë³€í™˜
                
                # ì œëª© íƒœê·¸ ì°¾ê¸° (desc ë‚´ë¶€ì˜ strong íƒœê·¸)
                title = img_tag.get("alt") if img_tag else "ì œëª©ì—†ìŒ"

                if href and img_src:
                    all_items.append({"title": title, "link": href, "image": img_src})

    print(f"âœ… ì´ {len(all_items)}ê°œ ìƒí’ˆ í¬ë¡¤ë§ ì™„ë£Œ!")
    return all_items
