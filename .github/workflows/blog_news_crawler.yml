name: Run Crawler Every Hour

on:
  schedule:
    - cron: '0 */4 * * *'  # 매시간 정각 실행
  workflow_dispatch:  # 수동 실행 가능

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
      - name: 저장소 체크아웃 (코드 가져오기)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GH_PAT }} 

      - name: Python 설정 (Python 3.9)
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: 필요한 패키지 설치
        run: |
          pip install requests requests-html beautifulsoup4 lxml urllib3 chardet lxml_html_clean pyppeteer

      - name: 크롤러 실행
        run: |
          export PYPPETEER_HEADLESS=True
          python main_crawler.py

      - name: Git 설정 및 변경 사항 확인
        run: |
          git config --global user.name "ric-grown"
          git config --global user.email "ric.richest@gmail.com"
          git add images/
          git status

      - name: GitHub PAT을 사용한 Push
        run: |
          git remote set-url origin https://x-access-token:${{ secrets.GH_PAT }}@github.com/ric-grown/news-bot.git
          git add *.json
          git commit -m "자동 크롤링 결과 업데이트 [GitHub Actions]" || echo "No changes to commit"
          git push origin main
