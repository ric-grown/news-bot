name: Run Crawler Every Hour

on:
  schedule:
    - cron: '0 * * * *'  # 매시간 0분마다 실행 (예: 01:00, 02:00, 03:00 ...)

  workflow_dispatch:  # 수동 실행 가능하도록 추가

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
      - name: 저장소 체크아웃 (코드 가져오기)
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: 실행 경로 확인 (디버깅)
        run: |
          git status  # ✅ 현재 디렉터리가 Git 저장소인지 확인

      - name: Python 설정 (Python 3.9)
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: 필요한 패키지 설치
        run: |
          pip install requests requests-html beautifulsoup4 lxml urllib3 chardet lxml_html_clean

      - name: 크롤러 실행
        run: |
          python main_crawler.py

      - name: Git 설정 및 변경사항 확인
        working-directory: /home/runner/work/news-bot
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git status

      - name: 변경 사항 커밋 & 푸시
        run: |
          git add *.json
          git commit -m "자동 크롤링 결과 업데이트 [GitHub Actions]" || echo "No changes to commit"
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
