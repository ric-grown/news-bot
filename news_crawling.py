from requests_html import HTMLSession
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import chardet
import time

# í¬ë¡¤ë§í•  URL ëª©ë¡
enter_urls = [
    "https://news.naver.com/main/ranking/popularDay.naver"
]

def crawl_news():
    # ì„¸ì…˜ ì‹œì‘
    session = HTMLSession()

    # ê²°ê³¼ ì €ì¥ ë¦¬ìŠ¤íŠ¸
    all_items = []

    # ê° ì¹´í…Œê³ ë¦¬ì— ëŒ€í•´ í¬ë¡¤ë§ ì‹¤í–‰
    for page_num, url in enumerate(enter_urls, start=1):
        print(f"ğŸ” ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì¤‘...")

        response = session.get(url)

        # ğŸ”¥ 1. ì¸ì½”ë”© ìë™ ê°ì§€ í›„ ì„¤ì •
        detected_encoding = chardet.detect(response.content)["encoding"]
        response.encoding = detected_encoding if detected_encoding else "utf-8"

        # ğŸ”¥ 2. JavaScript ë Œë”ë§ ì‹¤í–‰ (3ì´ˆ ëŒ€ê¸°)
        response.html.render(sleep=3)

        # ğŸ”¥ 3. `response.content`ì„ ì§ì ‘ `decode`í•˜ì—¬ í•œê¸€ ê¹¨ì§ ë°©ì§€
        html_content = response.content.decode(detected_encoding, errors="replace")

        # ğŸ”¥ 4. HTML íŒŒì‹±
        soup = BeautifulSoup(html_content, "html.parser")

        # ë©”ì¸ ë‰´ìŠ¤ ë­í‚¹ div ì°¾ê¸°
        main_div_tag = soup.find("div", class_="rankingnews_box_wrap")
        if main_div_tag:
            rankingnews_boxes = main_div_tag.find_all("div", class_="rankingnews_box")  # ì—¬ëŸ¬ ê°œì˜ ë‰´ìŠ¤ ë°•ìŠ¤
            
            for box in rankingnews_boxes:
                ul_tags = box.find_all("ul", class_="rankingnews_list")  # ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ ul ì°¾ê¸°
                
                for ul in ul_tags:
                    li_tags = ul.find_all("li")  # li íƒœê·¸ë“¤ ì°¾ê¸°
                    
                    for li in li_tags:
                    # ì œëª©ê³¼ ë§í¬ ì°¾ê¸° (ì²« ë²ˆì§¸ <a> íƒœê·¸)
                        title_tag = li.find("a", class_="list_title")
                        title = title_tag.text.strip() if title_tag else "ì œëª© ì—†ìŒ"
                        link = title_tag["href"] if title_tag and title_tag.has_attr("href") else None

                        if link:
                            article_response = session.get(link)
                            article_response.html.render(sleep=3)  # JavaScript ë Œë”ë§
                            article_soup = BeautifulSoup(article_response.html.html, "html.parser")
                            
                            img_tag = article_soup.find("img", id="img1")  # id="img1"ì¸ ì´ë¯¸ì§€ ì°¾ê¸°
                            img_src = img_tag["src"] if img_tag and img_tag.has_attr("src") else None
                            
                            if not img_src:
                                img_tag = article_soup.find("img", class_="_LAZY_LOADING_INIT_HIDE")
                                img_src = img_tag["data-src"] if img_tag and img_tag.has_attr("data-src") else None

                            if img_src:
                                all_items.append({"title": title, "link": link, "image": img_src})

                            # ë”œë ˆì´ ì¶”ê°€ (ê³¼ë¶€í•˜ ë°©ì§€)
                            time.sleep(1)

    print(f"âœ… ì´ {len(all_items)}ê°œ ìƒí’ˆ í¬ë¡¤ë§ ì™„ë£Œ!")
    return all_items
