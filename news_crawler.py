import requests
import json
import time
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# JSON íŒŒì¼ ì €ì¥ í•¨ìˆ˜
def save_to_json(data, filename="now_news.json"):
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    print(f"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filename}")

# ğŸ” 1. ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§
def get_naver_news():
    url = "https://news.naver.com/main/ranking/popularDay.naver"
    headers = {"User-Agent": "Mozilla/5.0"}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, "html.parser")
    
    news_list = []
    for item in soup.select(".rankingnews_box .list_content a")[:10]:
        title = item.text.strip()
        link = "https://news.naver.com" + item["href"] if item["href"].startswith("/") else item["href"]
        image = item.find_previous("img")["src"] if item.find_previous("img") else "https://via.placeholder.com/150"
        news_list.append({"title": title, "link": link, "image": image, "source": "ë„¤ì´ë²„ ë‰´ìŠ¤"})
    
    print("âœ” ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì™„ë£Œ.")
    return news_list

# ğŸ” 2. ë„¤ì´ë²„ ì¸ê¸° ë¸”ë¡œê·¸ í¬ë¡¤ë§
def get_naver_blogs():
    url = "https://section.blog.naver.com/BlogHome.naver?directoryNo=0&currentPage=1&groupId=0"
    options = Options()
    options.add_argument("--headless")
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.get(url)
    
    wait = WebDriverWait(driver, 10)
    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "section.hot_topic")))
    
    blog_list = []
    blog_elements = driver.find_elements(By.CSS_SELECTOR, "section.hot_topic .list_hottopic .item")[:5]
    
    for blog in blog_elements:
        try:
            title = blog.find_element(By.CSS_SELECTOR, ".title_post").text.strip()
            link = blog.find_element(By.CSS_SELECTOR, "a.item_inner").get_attribute("href")
            image = blog.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
            blog_list.append({"title": title, "link": link, "image": image, "source": "ë„¤ì´ë²„ ë¸”ë¡œê·¸"})
        except:
            continue
    
    driver.quit()
    print("âœ” ë„¤ì´ë²„ ë¸”ë¡œê·¸ í¬ë¡¤ë§ ì™„ë£Œ.")
    return blog_list

# ğŸ” 3. í‹°ìŠ¤í† ë¦¬ ì¸ê¸° ë¸”ë¡œê·¸ í¬ë¡¤ë§
def get_tistory_blogs():
    url = "https://www.tistory.com/category/ranking"
    options = Options()
    options.add_argument("--headless")
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.get(url)
    
    wait = WebDriverWait(driver, 10)
    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "div.cont_g")))
    
    tistory_list = []
    post_elements = driver.find_elements(By.CSS_SELECTOR, "div.cont_g")[:5]
    
    for post in post_elements:
        try:
            title = post.find_element(By.CSS_SELECTOR, "strong.tit_g").text.strip()
            link = post.find_element(By.CSS_SELECTOR, "a.link_cont.zoom_cont").get_attribute("href")
            image = post.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
            tistory_list.append({"title": title, "link": link, "image": image, "source": "í‹°ìŠ¤í† ë¦¬"})
        except:
            continue
    
    driver.quit()
    print("âœ” í‹°ìŠ¤í† ë¦¬ ë¸”ë¡œê·¸ í¬ë¡¤ë§ ì™„ë£Œ.")
    return tistory_list

# ğŸ”„ ì „ì²´ ì‹¤í–‰
def main():
    print("ğŸš€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    naver_news = get_naver_news()
    naver_blogs = get_naver_blogs()
    tistory_blogs = get_tistory_blogs()
    
    all_data = naver_news + naver_blogs + tistory_blogs
    save_to_json(all_data)
    print("ğŸ‰ ëª¨ë“  í¬ë¡¤ë§ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
